---
title: "Simple_sim_vignette_2"
author: "Matthew Stephens"
date: "May 26, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Goal

To try out some simulations that don't match the canonical covariance matrices and see if the data driven matrices help.

# Simple simulation

Just set up data 
```{r}
  library("mashr2")
  set.seed(1)
  data = simple_sims2(1000,1)
  true.U1 = cbind(c(1,1,0,0,0),c(1,1,0,0,0),rep(0,5),rep(0,5),rep(0,5))
  true.U2 = cbind(rep(0,5),rep(0,5),c(0,0,1,1,1),c(0,0,1,1,1),c(0,0,1,1,1))
  Utrue = list(true.U1 = true.U1, true.U2 = true.U2)
```
  
  
Run 1-by-1 to add the strong signals and ed covariances
```{r}
  m.1by1 = mash_run_1by1_new(data$Bhat, data$Shat)
  strong = get_significant_results(m.1by1)
  U1 = cov_canonical(data)
  U2 = cov_data_driven(data, strong) # adds covariance matrices based on extreme deconvolution, initialized from pca
  
  m.1 = mash_new(data$Bhat,data$Shat, U1)
  m.2 = mash_new(data$Bhat,data$Shat, U2)
  m.3 = mash_new(data$Bhat,data$Shat, c(U1,U2))
  m.4 = mash_new(data$Bhat,data$Shat, Utrue)
  m.5 = mash_new(data$Bhat,data$Shat, c(Utrue,U1,U2))
  m.1$loglik
  m.2$loglik
  m.3$loglik
  m.4$loglik
  m.5$loglik
  m.1by1$loglik
```


The log likelihood is much better from data-driven than canonical covariances, but still better with the true matrices. This is good!


