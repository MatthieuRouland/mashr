<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>eQTL analysis outline • mashr</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><meta property="og:title" content="eQTL analysis outline">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">mashr</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">Home</a>
</li>
<li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="http://github.com/stephenslab/mashr">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>eQTL analysis outline</h1>
                        <h4 class="author">Matthew Stephens</h4>
            
            <h4 class="date">2019-03-11</h4>
          </div>

    
    
<div class="contents">
<div id="introduction" class="section level1">
<h1 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h1>
<p>In the introductory <code>mashr</code> vignettes we assumed that the data were small enough that it was convenient to read them all in and do all the analyses on the same data.</p>
<p>In larger applications, particularly eQTL studies, it can be more convenient to do different parts of the analyses on subsets of the tests. Specifically, if you have millions of tests in dozens of conditions, it might be helpful to consider subsets of these millions of tests at any one time. Here we illustrate this idea.</p>
<p>Our suggested workflow is to extract (at least) two subsets of tests from your complete data set:</p>
<ol style="list-style-type: decimal">
<li><p>Results from a subset of “strong” tests corresponding to stronger effects in your study. For example, these tests might have been identified by taking the “top” eQTL in each gene based on univariate test results, or by some other approach such as a simple meta-analysis.</p></li>
<li><p>Results from a <em>random subset</em> of all tests. It is important that these be an unbiased representation of all the tests you are considering, including null and non-null tests, because <code>mashr</code> uses these tests to learn about the amount of signal in the data, and to “correct” estimates for the fact that many tests are null (analagous to a kind of multiple testing correction.)</p></li>
</ol>
<p>We will call the data from these two sets of tests <code>strong</code> and <code>random</code> respectively.</p>
<p>To give some sense of the potential appropriate sizes of these datasets: in our eQTL application in <a href="https://www.biorxiv.org/content/early/2017/05/09/096552">Urbut et al</a>, the <code>strong</code> data contained about 16k tests (the top eQTL per gene), and for the <code>random</code> data we used 20k randomly-selected tests. (If you suspect true effects are very sparse then you might want to increase the size of the random subset, say to 200k).</p>
<div id="analysis-strategy-outline" class="section level2">
<h2 class="hasAnchor">
<a href="#analysis-strategy-outline" class="anchor"></a>Analysis strategy outline</h2>
<p>The basic analysis strategy is now:</p>
<ol style="list-style-type: decimal">
<li><p>Learn correlation structure among null tests using <code>random</code> test.</p></li>
<li><p>Learn data-driven covariance matrices using <code>strong</code> tests.</p></li>
<li><p>Fit the mashr model to the <code>random</code> tests, to learn the mixture weights on all the different covariance matrices and scaling coefficients.</p></li>
<li><p>Compute posterior summaries on the <code>strong</code> tests, using the model fit from step 2. (At this stage you could actually compute posterior summaries for any sets of tests you like. For example you could read in all your tests in small batches and compute posterior summaries in batches. But for illustration we will just do it on the <code>strong</code> tests.)</p></li>
</ol>
</div>
</div>
<div id="example" class="section level1">
<h1 class="hasAnchor">
<a href="#example" class="anchor"></a>Example</h1>
<p>First we simulate some data to illustrate the ideas. To make this convenient to run we simulate a small data. And we identify the strong hits using <code>mash_1by1</code>. But in practice you may want to use methods outside of R to extract the matrices of data corresponding to strong and random tests, and then read them in as you need them. For example, see <a href="https://github.com/stephenslab/gtexresults/blob/master/workflows/fastqtl_to_mash.ipynb">here</a> for scripts we use for processing fastQTL output.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ashr)
<span class="kw">library</span>(mashr)
<span class="kw">set.seed</span>(<span class="dv">1</span>)
simdata =<span class="st"> </span><span class="kw"><a href="../reference/simple_sims.html">simple_sims</a></span>(<span class="dv">10000</span>,<span class="dv">5</span>,<span class="dv">1</span>) <span class="co"># simulates data on 40k tests</span>

<span class="co"># identify a subset of strong tests</span>
m.1by1 =<span class="st"> </span><span class="kw"><a href="../reference/mash_1by1.html">mash_1by1</a></span>(<span class="kw"><a href="../reference/mash_set_data.html">mash_set_data</a></span>(simdata<span class="op">$</span>Bhat,simdata<span class="op">$</span>Shat))
strong.subset =<span class="st"> </span><span class="kw"><a href="../reference/get_significant_results.html">get_significant_results</a></span>(m.1by1,<span class="fl">0.05</span>)

<span class="co"># identify a random subset of 5000 tests</span>
random.subset =<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(simdata<span class="op">$</span>Bhat),<span class="dv">5000</span>)</code></pre></div>
<div id="correlation-structure" class="section level2">
<h2 class="hasAnchor">
<a href="#correlation-structure" class="anchor"></a>Correlation structure</h2>
<p>We estimate the correlation structure in the null tests from the <code>random</code> data (not the <code>strong</code> data because they will not necessarily contain any null tests).</p>
<p>To do this we set up a temporary data object <code>data.temp</code> from the random tests and use <code>estimate_null_correlation_simple</code> as in <a href="intro_correlations">this vignette</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data.temp =<span class="st"> </span><span class="kw"><a href="../reference/mash_set_data.html">mash_set_data</a></span>(simdata<span class="op">$</span>Bhat[random.subset,],simdata<span class="op">$</span>Shat[random.subset,])
Vhat =<span class="st"> </span><span class="kw"><a href="../reference/estimate_null_correlation_simple.html">estimate_null_correlation_simple</a></span>(data.temp)
<span class="kw">rm</span>(data.temp)</code></pre></div>
<p>Now we can set up our main data objects with this correlation structure in place:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data.random =<span class="st"> </span><span class="kw"><a href="../reference/mash_set_data.html">mash_set_data</a></span>(simdata<span class="op">$</span>Bhat[random.subset,],simdata<span class="op">$</span>Shat[random.subset,],<span class="dt">V=</span>Vhat)
data.strong =<span class="st"> </span><span class="kw"><a href="../reference/mash_set_data.html">mash_set_data</a></span>(simdata<span class="op">$</span>Bhat[strong.subset,],simdata<span class="op">$</span>Shat[strong.subset,], <span class="dt">V=</span>Vhat)</code></pre></div>
</div>
<div id="data-driven-covariances" class="section level2">
<h2 class="hasAnchor">
<a href="#data-driven-covariances" class="anchor"></a>Data driven covariances</h2>
<p>Now we use the strong tests to set up data-driven covariances.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">U.pca =<span class="st"> </span><span class="kw"><a href="../reference/cov_pca.html">cov_pca</a></span>(data.strong,<span class="dv">5</span>)
U.ed =<span class="st"> </span><span class="kw"><a href="../reference/cov_ed.html">cov_ed</a></span>(data.strong, U.pca)</code></pre></div>
</div>
<div id="fit-mash-model-estimate-mixture-proportions" class="section level2">
<h2 class="hasAnchor">
<a href="#fit-mash-model-estimate-mixture-proportions" class="anchor"></a>Fit mash model (estimate mixture proportions)</h2>
<p>Now we fit mash to the random tests using both data-driven and canonical covariances. (Remember the Crucial Rule! We have to fit using a random set of tests, and not a dataset that is enriched for strong tests.) The <code>outputlevel=1</code> option means that it will not compute posterior summaries for these tests (which saves time).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">U.c =<span class="st"> </span><span class="kw"><a href="../reference/cov_canonical.html">cov_canonical</a></span>(data.random)
m =<span class="st"> </span><span class="kw"><a href="../reference/mash.html">mash</a></span>(data.random, <span class="dt">Ulist =</span> <span class="kw">c</span>(U.ed,U.c), <span class="dt">outputlevel =</span> <span class="dv">1</span>)</code></pre></div>
<pre><code>#  - Computing 5000 x 241 likelihood matrix.
#  - Likelihood calculations took 0.14 seconds.
#  - Fitting model with 241 mixture components.
#  - Model fitting took 2.10 seconds.</code></pre>
</div>
<div id="compute-posterior-summaries" class="section level2">
<h2 class="hasAnchor">
<a href="#compute-posterior-summaries" class="anchor"></a>Compute posterior summaries</h2>
<p>Now we can compute posterior summaries etc for any subset of tests using the above mash fit. Here we do this for the <code>strong</code> tests. We do this using the same <code>mash</code> function as above, but we specify to use the fit from the previous run of mash by specifying<br><code>g=get_fitted_g(m), fixg=TRUE</code>. (In <code>mash</code> the parameter <code>g</code> is used to denote the mixture model which we learned above.)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m2 =<span class="st"> </span><span class="kw"><a href="../reference/mash.html">mash</a></span>(data.strong, <span class="dt">g=</span><span class="kw"><a href="http://www.rdocumentation.org/packages/ashr/topics/get_lfdr">get_fitted_g</a></span>(m), <span class="dt">fixg=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>#  - Computing 1428 x 241 likelihood matrix.
#  - Likelihood calculations took 0.06 seconds.
#  - Computing posterior matrices.
#  - Computation allocated took 0.01 seconds.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/ashr/topics/get_lfdr">get_lfsr</a></span>(m2))</code></pre></div>
<pre><code>#               condition_1  condition_2  condition_3  condition_4
# effect_13096 1.351029e-05 7.304550e-01 6.633768e-01 6.419718e-01
# effect_29826 4.749262e-05 6.730004e-01 6.283735e-01 7.309554e-01
# effect_14042 6.116539e-02 1.556075e-02 1.341717e-02 4.594320e-02
# effect_12524 5.552693e-01 7.011304e-01 5.154365e-01 2.625457e-05
# effect_15456 8.487950e-05 5.662427e-01 4.228120e-01 6.055155e-01
# effect_35844 6.452969e-10 3.804030e-10 1.797445e-08 1.206916e-10
#               condition_5
# effect_13096 8.025795e-01
# effect_29826 6.232960e-01
# effect_14042 6.049099e-06
# effect_12524 5.527004e-01
# effect_15456 4.885029e-01
# effect_35844 5.432876e-12</code></pre>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li>
<a href="#introduction">Introduction</a><ul class="nav nav-pills nav-stacked">
<li><a href="#analysis-strategy-outline">Analysis strategy outline</a></li>
      </ul>
</li>
      <li>
<a href="#example">Example</a><ul class="nav nav-pills nav-stacked">
<li><a href="#correlation-structure">Correlation structure</a></li>
      <li><a href="#data-driven-covariances">Data driven covariances</a></li>
      <li><a href="#fit-mash-model-estimate-mixture-proportions">Fit mash model (estimate mixture proportions)</a></li>
      <li><a href="#compute-posterior-summaries">Compute posterior summaries</a></li>
      </ul>
</li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Matthew Stephens, Sarah Urbut, Gao Wang, Yuxin Zou, Peter Carbonetto.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
